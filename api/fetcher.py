import asyncio
import logging
import os

from aiohttp import ClientTimeout

API_URL = os.getenv("OPEN_API_URL")
TIMEOUT = ClientTimeout(total=100)
MAX_CONCURRENCY = 10
SEMAPHORE = asyncio.Semaphore(MAX_CONCURRENCY)

logger = logging.getLogger(__name__)


async def fetch_page(session, instt_code, page, semaphore):
    params = {
        "serviceKey": os.getenv("OPEN_API_KEY_PUBLIC"),
        "pageNo": page,
        "numOfRows": 1500,
        "type": "json",
        "instt_code": instt_code
    }

    async with semaphore:
        try:
            async with session.get(API_URL, params=params, timeout=TIMEOUT) as resp:
                resp.raise_for_status()
                data = await resp.json()
                return data.get("response", {}).get("body", {}).get("items", [])
        except asyncio.TimeoutError:
            logger.error(f"TimeoutError - ê¸°ê´€ì½”ë“œ: {instt_code}, í˜ì´ì§€: {page}")
        except Exception as e:
            logger.exception(f"ê¸°íƒ€ ì˜¤ë¥˜ ë°œìƒ - ê¸°ê´€ì½”ë“œ: {instt_code}, í˜ì´ì§€: {page} - {e}")
        return []


async def fetch_and_parse(session, instt_code, region_name, semaphore):
    items = []
    page = 1
    numOfRows = 1500

    while True:
        page_items = await fetch_page(session, instt_code, page, semaphore)
        if not page_items:
            break

        items.extend(page_items)

        if len(page_items) < numOfRows:
            break

        page += 1

    logger.info(f"ğŸ“¦ {region_name} ìˆ˜ì§‘ ì™„ë£Œ - ì´ {len(items)}ê±´")
    return items
